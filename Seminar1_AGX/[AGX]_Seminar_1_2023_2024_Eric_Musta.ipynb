{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79E5BMffKNq7"
      },
      "source": [
        "# Seminar 1 - A Song of Graphs and Search\n",
        "\n",
        "---\n",
        "\n",
        "**Course**: Graphs and Network Analysis\n",
        "\n",
        "**Degree**: Artificial Intelligence Degree (UAB)\n",
        "\n",
        "**Topic**: Practical seminar that includes exercises from units 1 to 6\n",
        "\n",
        "**Activity description**: Most of us are familiar with the Game of Thrones books or series. For those who do not know it, it is a fictional series from the HBO chain, inspired by the series of novels \"A Song of Ice and Fire\", which tells the experiences of a group of characters from different noble houses on the fictional continent of *Westeros* to have control of the Iron Throne and rule the seven kingdoms that make up the territory. The series' success has spawned many blogs and other sources about the series, with additional resources. The graphs that we propose to use in this exercise represent the characters of the series (or books) as nodes, and their co-appearance in a scene (the weights of the edges are higher if two characters appear simultaneously more times). So we have a social network of characters. We will use these graphs to work on some of the concepts seen in the first units of the course (graph and node metrics, search and routes). Finally, synthetic graphs that simulate a realistic network will be generated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLiz4rCDKvnz"
      },
      "source": [
        "## Qualification\n",
        "\n",
        "**Submission**: An '.ipynb' file from the colab corresponding to each group will be delivered (this very same file, adding the code blocks and explanations that correspond to each activity). To get the file you will need to go to File --> Download. Remember that you will have to answer and analyze the different problems. Coding alone will NOT be evaluated: explaining and reasoning about the solution of the problem is essential. **You should provide explanations of the obtained results for at least the exercises marked with the ðŸ’¬ symbol**.\n",
        "The outcome of this seminar will thus be an analysis of the network at different levels: global metrics, node importance, shortest paths, random graphs, and visualization.\n",
        "\n",
        "**Delivery form**: The work must be done in **groups of two people** and delivered through the virtual campus (in the section corresponding to Seminar 1).\n",
        "\n",
        "**Doubts**: For any questions, apart from class sessions, you can contact cristina.perez@uab.cat.\n",
        "\n",
        "**Deadline**: March 13th (during all day).\n",
        "\n",
        "**Marks**: The grade of the seminars (seminar 1 + seminar 2) has a weight of 10% on the final grade of the subject.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mN24cx9gHve"
      },
      "source": [
        "# Authors\n",
        "\n",
        "**Lab group:** GrupLab-9\n",
        "\n",
        "**Student 1 - Name (NIU): 1668936**\n",
        "\n",
        "**Student 2 - Name (NIU): 1672981**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2qbjyP1Dies"
      },
      "source": [
        "## 1. Environment setup\n",
        "----\n",
        "\n",
        "The main libraries that will be used in this seminar are the following:\n",
        "\n",
        "* [NetworkX](https://networkx.github.io/)\n",
        "* [Pandas](https://pandas.pydata.org/)\n",
        "* [Matplotlib](https://matplotlib.org/)\n",
        "* [NumPy](https://numpy.org/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PWbwZx7z0Ek"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade scipy networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSnP2jzpDiB4"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y graphviz libgraphviz-dev pkg-config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygraphviz"
      ],
      "metadata": {
        "id": "6L5me_bIcbFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai3-8Rz2zAFD"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from networkx.drawing.nx_agraph import graphviz_layout\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jPVT43xAiSm"
      },
      "source": [
        "## 2. Data collection\n",
        "\n",
        "---\n",
        "\n",
        "This seminar is based on data from *Game of Thrones* and \"A Song of Ice and Fire\" curated by Andrew Beveridge. Data is available from two different github repositories:\n",
        "\n",
        "* [Book to Network](https://github.com/mathbeveridge/asoiaf)\n",
        "* [Script to Network](https://github.com/mathbeveridge/gameofthrones)\n",
        "\n",
        "In each of them, there is a *data* folder with several *.csv* files that encode nodes and edges of different networks.\n",
        "\n",
        "To download the data in the *colab* environment you can run the following command:\n",
        "\n",
        "```\n",
        "$ !wget https://raw.githubusercontent.com/mathbeveridge/repo_name/master/data/file_id-nodes.csv\n",
        "$ !wget https://raw.githubusercontent.com/mathbeveridge/repo_name/master/data/file_id-edges.csv\n",
        "```\n",
        "\n",
        "\n",
        "where,\n",
        "\n",
        "* **repo_name** is the name of the repository, *asoiaf* for the Books and *gameofthrones* for the Script.\n",
        "* **file_id** is the ID of the file you can find with the link. This indicates the book or season number.\n",
        "\n",
        "For example, to download the graph of the first season of the series, we would run:\n",
        "\n",
        "```\n",
        "$ !wget https://raw.githubusercontent.com/mathbeveridge/gameofthrones/master/data/got-s1-nodes.csv\n",
        "$ !wget https://raw.githubusercontent.com/mathbeveridge/gameofthrones/master/data/got-s1-edges.csv\n",
        "```\n",
        "\n",
        "The downloaded files can be found in */content/file_name*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7FtY-xO2vfv"
      },
      "source": [
        "For this activity, we will work with the graph generated from all the books.\n",
        "\n",
        "\n",
        "*  **Download the two .csv files corresponding to the graph generated from all the books (asoiaf-all)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBFCzKx6AmOq"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/mathbeveridge/asoiaf/master/data/asoiaf-all-nodes.csv\n",
        "!wget https://raw.githubusercontent.com/mathbeveridge/asoiaf/master/data/asoiaf-all-edges.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twfpe2fpAptq"
      },
      "source": [
        "## 3. Data load\n",
        "\n",
        "---\n",
        "\n",
        "The function *csv_to_graph()* creates a NetworkX graph from the *.csv* files encoding edges and nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd2_o4UZAqN7"
      },
      "outputs": [],
      "source": [
        "def csv_to_graph(file_id_nodes: str, file_id_edges: str, origin: str = 'book') \\\n",
        "                    -> nx.graph:\n",
        "    \"\"\"Return a nx.graph\n",
        "\n",
        "    Build a graph given a csv file for nodes and edge.\n",
        "    origin controls the source of the graph to adapt the node features.\n",
        "    \"\"\"\n",
        "\n",
        "    if origin == 'book':\n",
        "        key1, key2 = 'weight', 'book'\n",
        "    elif origin == 'script':\n",
        "        key1, key2 = 'Weight', 'Season'\n",
        "    else:\n",
        "        raise NameError('Unknown origin {}'.format(origin))\n",
        "\n",
        "    nodes = pd.read_csv(file_id_nodes)\n",
        "    edges = pd.read_csv(file_id_edges)\n",
        "\n",
        "    if key2 not in edges:\n",
        "        key2 = 'id'\n",
        "\n",
        "    g = nx.Graph()\n",
        "    for row in nodes.iterrows():\n",
        "        g.add_node(row[1]['Id'], name=row[1]['Label'])\n",
        "\n",
        "    for row in edges.iterrows():\n",
        "        g.add_edge(row[1]['Source'],row[1]['Target'],\n",
        "                   weight=1/row[1][key1], id=row[1][key2])\n",
        "\n",
        "    return g\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXfsNMBoBA0u"
      },
      "source": [
        "* **Create a NetworkX graph from the downloaded files using the `csv_to_graph` function.** [Optionally, you can repeat the process with the graph generated from the series]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bkvDRy4BG_-"
      },
      "outputs": [],
      "source": [
        "g_book = csv_to_graph('asoiaf-all-nodes.csv', 'asoiaf-all-edges.csv', origin='book')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYA9HhHfTF5J"
      },
      "source": [
        "* **Generate a first exploratory visualization of the graph.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8Zft9qsFpM3"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [12, 12]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "pos = graphviz_layout(g_book, prog=\"neato\")\n",
        "nx.draw(g_book, pos, with_labels=False, arrows=False, node_size=30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3NMU6sFTWah"
      },
      "source": [
        "## 4. General graph metrics\n",
        "---\n",
        "\n",
        "Perform a general summary of the Network properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ5QMkkdTcez"
      },
      "source": [
        "* **ðŸ’¬  Obtain the order, size and density of the graph, as well as the average degree of its nodes.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhMIYrihTfGz"
      },
      "outputs": [],
      "source": [
        "graph_order = g_book.order()\n",
        "graph_size = g_book.size()\n",
        "graph_density = nx.density(g_book)\n",
        "average_degree = np.mean(list(dict(g_book.degree()).values()))\n",
        "print('Order:', graph_order)\n",
        "print('Size:', graph_size)\n",
        "print('Density:', graph_density)\n",
        "print('Average degree:', average_degree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIqk5NY-e97f"
      },
      "source": [
        "ðŸ’¬ :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UNE33UKTeJb"
      },
      "source": [
        "* **Check that it is a connected undirected graph.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ac20vgWUM8S"
      },
      "outputs": [],
      "source": [
        "# check that is a connected undirected graph\n",
        "print('Is connected:', nx.is_connected(g_book))\n",
        "print('Is undirected:', not nx.is_directed(g_book))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4a8idcD49W_"
      },
      "source": [
        "* **ðŸ’¬ Make a small report on the metrics of the given graph (diameter, radius, average network distance, clustering coefficient).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpQpgHRIth7N"
      },
      "outputs": [],
      "source": [
        "print(\"diameter:\", nx.diameter(g_book))\n",
        "print(\"radius:\", nx.radius(g_book))\n",
        "print(\"average network distance:\", nx.average_shortest_path_length(g_book))\n",
        "print(\"average clustering coefficient:\", nx.average_clustering(g_book))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAgSjt-dfE_P"
      },
      "source": [
        "ðŸ’¬ :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMiA4hFQU7hX"
      },
      "source": [
        "## 5. Centrality metrics: Characters' importance\n",
        "---\n",
        "\n",
        "\n",
        "In this section, we will study the importance of the characters according to their centrality in the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U12IpA9BU_TD"
      },
      "source": [
        "* **Compute the 10 most central nodes in the network taking into account the different types of centrality (degree, betweenness, closeness and eigenvector centrality). Moreover, use page rank to assess importance of the characters.**\n",
        "\n",
        "  * *centrality_bar_plot()*: Given the corresponding centrality draw a bar graph.\n",
        "  * ðŸ’¬ Try to reason about the changes that occur with the different types of centrality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0_uGmLkVCms"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def centrality_bar_plot(centrality, name='betweenness', n=10):\n",
        "    # take the top n nodes by quantity of centrality\n",
        "    centrality = dict(Counter(centrality).most_common(n))\n",
        "    values = list(centrality.values())\n",
        "    label = list(centrality.keys())\n",
        "\n",
        "    df = pd.DataFrame({'Name': label, name: values})\n",
        "    ax = df.plot.bar(x='Name', y=name, rot=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI9WHb_pVG3i"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [10, 4]\n",
        "\n",
        "degree_centrality = nx.degree_centrality(g_book) # Degree Centrality\n",
        "betweenness_centrality = nx.betweenness_centrality(g_book) # Betweenness Centrality\n",
        "closeness_centrality = nx.closeness_centrality(g_book) # Closeness Centrality\n",
        "eigen_centrality = nx.eigenvector_centrality(g_book) # Eigenvector Centrality\n",
        "\n",
        "\n",
        "centrality_bar_plot(degree_centrality, name='degree')\n",
        "centrality_bar_plot(betweenness_centrality, name='betweenness')\n",
        "centrality_bar_plot(closeness_centrality, name='closeness')\n",
        "centrality_bar_plot(eigen_centrality, name='eigen')\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [12, 12]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koaKpy3NPlrg"
      },
      "outputs": [],
      "source": [
        "# Page rank to assess the importance of the characters\n",
        "page_rank = nx.pagerank(g_book)\n",
        "centrality_bar_plot(page_rank, name='page_rank')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfkufO5EfHMb"
      },
      "source": [
        "ðŸ’¬ : In the closeness centrality there doesn't seem to be a significant difference out of the top 10 nodes. The measure shows when a node is near the center of the network, so all other nodes have a very similar value because they're really close to the center.\n",
        "\n",
        "In the betweenness centrality bar plot, we can visualize a gradual difference in value for the nodes. We start with a node that has a really high value (the center) and clearly the node is relevant in the information flow since it's the one that brokers between groups the most. As we reach for the neighbors of this node, this value decreases because we're incrementing the distance between the highest node and the others.\n",
        "\n",
        "As for the degree centrality, the plot shows also a gradual decrease, which is normal because all 10 nodes don't hold the same importance in the graph as we see that their connections decrease as we go through each node. This is an usual pattern in the context of social networks when the node that has the most followers is the most important while the rest have more or less an average number of followers which is usually much more lower.\n",
        "\n",
        "In the eigenvector centrality, we see the same pattern, the latter nodes are connected to less important nodes and have a lower degree centrality, while the highest are connected to more influential nodes. As we go through the nodes we notice a decrease in this number.\n",
        "\n",
        "In page rank, we have more or less the same as in the degree centrality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzdW06TWLpgE"
      },
      "source": [
        "* **What is the subgraph generated by the best connected characters?**\n",
        "  * Use closeness centrality to generate the graph of the 25 most central characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP0PDNFROlzA"
      },
      "outputs": [],
      "source": [
        "def centrality_subgraph(g, centrality, name='closeness', n=25):\n",
        "    centrality = dict(Counter(centrality).most_common(n))\n",
        "    nodes = list(centrality.keys())\n",
        "    sg = g.subgraph(nodes)\n",
        "    plt.title('Top {} nodes by {}'.format(n, name))\n",
        "    pos = graphviz_layout(sg, prog=\"neato\")\n",
        "    nx.draw(sg, pos, with_labels=True, arrows=False, node_size=30)\n",
        "    plt.show()\n",
        "    return sg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQI3uYUVQC7K"
      },
      "outputs": [],
      "source": [
        "g_subgraph = centrality_subgraph(g_book, closeness_centrality, name='closeness_centrality', n=25)\n",
        "print(g_subgraph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QAANoAzQkIg"
      },
      "source": [
        "* **Draw this subgraph where the nodes are of size proportional to their centrality. Mark the most central and the less central node in the graph (for instance, use the color of the node to highlight it).**\n",
        "  * Use *closeness centrality* and scale it appropriately to emphasize the importance of different nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrmPPrnLQg-_"
      },
      "outputs": [],
      "source": [
        "def centrality_subgraph(g, centrality, name='closeness', n=25):\n",
        "    centrality = dict(Counter(centrality).most_common(n))\n",
        "    nodes = list(centrality.keys())\n",
        "    sg = g.subgraph(nodes)\n",
        "\n",
        "    node_sizes = [v * 5000 for v in centrality.values()]\n",
        "\n",
        "    most_central_node = max(centrality, key=centrality.get)\n",
        "    least_central_node = min(centrality, key=centrality.get)\n",
        "\n",
        "    plt.title('Top {} nodes by {}'.format(n, name))\n",
        "    pos = nx.spring_layout(sg)\n",
        "    nx.draw(sg, pos, with_labels=True, arrows=False, node_size=node_sizes, cmap=plt.cm.Blues)\n",
        "    nx.draw_networkx_nodes(sg, pos, nodelist=[most_central_node], node_color='red', node_size=node_sizes[0])\n",
        "    nx.draw_networkx_nodes(sg, pos, nodelist=[least_central_node], node_color='green', node_size=node_sizes[-1])\n",
        "\n",
        "    plt.show()\n",
        "    return sg\n",
        "\n",
        "g_subgraph = centrality_subgraph(g_book, closeness_centrality, name='closeness_centrality', n=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrcyWVDeSbKm"
      },
      "source": [
        "* **Draw the tree that the BFS and DFS algorithm would generate to traverse the graph starting from the least central node of the network according to *closeness centrality*.**\n",
        "  * Use *closeness centrality* and scale it appropriately to emphasize the importance of different nodes.\n",
        "  * To get the positions of the nodes, you can use the `graphviz_layout(tree, prog='dot')` command.\n",
        "  * ðŸ’¬ Comment on the obtained result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWqBU-pgGEN1"
      },
      "outputs": [],
      "source": [
        "least_central_node = min(closeness_centrality, key=closeness_centrality.get)\n",
        "\n",
        "bfs_tree = nx.bfs_tree(g_book, least_central_node)\n",
        "\n",
        "dfs_tree = nx.dfs_tree(g_book, least_central_node)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.title('BFS Tree')\n",
        "bfs_pos = graphviz_layout(bfs_tree, prog='dot')\n",
        "nx.draw(bfs_tree, pos=bfs_pos, with_labels=False, node_size=250, node_color='red')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('DFS Tree')\n",
        "dfs_pos = graphviz_layout(dfs_tree, prog='dot')\n",
        "nx.draw(dfs_tree, pos=dfs_pos, with_labels=False, node_size=250, node_color='green')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvC9X71WfJPN"
      },
      "source": [
        "ðŸ’¬ : The BFS tree indeed goes through the nodes by levels as seen in the plot while the DFS tree goes through a branch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPw518z4bm6X"
      },
      "source": [
        "* **ðŸ’¬ Compute the shortest path between the least and the most central nodes in the complete graph.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74EyetBvbmZT"
      },
      "outputs": [],
      "source": [
        "least_central_node = min(closeness_centrality, key=closeness_centrality.get)\n",
        "\n",
        "most_central_node = max(closeness_centrality, key=closeness_centrality.get)\n",
        "\n",
        "shortest_path = nx.shortest_path(g_book, source=least_central_node, target=most_central_node)\n",
        "\n",
        "print(\"Shortest path between the least and the most central nodes:\", shortest_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P64h9BCGfKQ5"
      },
      "source": [
        "ðŸ’¬ :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMmjlE6PLbNa"
      },
      "source": [
        "## 6. Random graph models\n",
        "----\n",
        "Up to this point, we have worked with a graph generated from the data extracted from the *Song of Ice and Fire* books. In the real world, however, obtaining the data needed to construct this graph can become very complex and expensive. This is one of the reasons why, over time, the synthetic generation of graphs has been studied.\n",
        "\n",
        "In this section we will work on the different models described in class. We will generate random graphs and study their properties.\n",
        "\n",
        "* **Generate random graphs with the Uniform, Gilbert and BarabÃ¡si-Albert models. Fix the number of nodes to the order of the studied graph. Adjust the rest of the parameters of the graph generation function to obtain graphs with similar number of edges.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSPp0obZZ5ga"
      },
      "outputs": [],
      "source": [
        "nedges = g_book.number_of_edges()\n",
        "nnodes = g_book.number_of_nodes()\n",
        "seed = 42\n",
        "print(nnodes, nedges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR-_Q4tIaiDP"
      },
      "source": [
        "### ErdÃ¶s-RÃ©ny: Uniform Model (gnm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMzeVY2GOnl1"
      },
      "outputs": [],
      "source": [
        "g_uniform = nx.gnm_random_graph(nnodes, nedges, seed=seed)\n",
        "print(g_uniform.number_of_nodes(), g_uniform.number_of_edges())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jx8XqxAWOk6"
      },
      "source": [
        "### ErdÃ¶s-RÃ©ny: Gilbert Model (gnp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KanjwpLRL3k"
      },
      "outputs": [],
      "source": [
        "total_edges = nnodes*(nnodes-1)/2\n",
        "g_gilbert = nx.gnp_random_graph(nnodes, p=nedges/total_edges, seed=seed)\n",
        "print(g_gilbert.number_of_nodes(), g_gilbert.number_of_edges())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWTrYow_WQR3"
      },
      "source": [
        "### BarabÃ¡si-Albert Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSw72kqvRYzx"
      },
      "outputs": [],
      "source": [
        "# we compute m\n",
        "g_barbasi = nx.barabasi_albert_graph(n=nnodes, m=4, seed=seed)\n",
        "print(g_barbasi.number_of_nodes(), g_barbasi.number_of_edges())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lECOPqH-bku6"
      },
      "outputs": [],
      "source": [
        "g_dict = {'Book': g_book, 'Uniform': g_uniform, 'Erdos': g_gilbert, 'Barbasi': g_barbasi}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkksiBi8MYII"
      },
      "source": [
        "* **ðŸ’¬ Show the order and size of the graph as well as the average degree and clustering coefficient of its nodes. Compute also the intervals between the maximum and minimum centralities for each family of synthetic graphs. Make a small report of the main metrics. Which random graph resembles more closely the graph from the books?**\n",
        "     * You can set the graph generation using a random seed. This way, two different runs will generate exactly the same graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax0Z-_edMgwW"
      },
      "outputs": [],
      "source": [
        "for k, g in g_dict.items():\n",
        "\tprint(\"------\", k, \"------\")\n",
        "\tprint(\"Order of: {}\".format(g.order()))\n",
        "\tprint(\"Size of: {}\".format(g.size()))\n",
        "\tprint(\"Average degree of: {}\".format(np.mean(list(dict(g.degree()).values()))))\n",
        "\tprint(\"Average clustering coefficient: {}\".format(nx.average_clustering(g)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXHQs9eUZ5gb"
      },
      "outputs": [],
      "source": [
        "for k, g in g_dict.items():\n",
        "\tdeg_centrality = nx.degree_centrality(g)\n",
        "\tmax_dc = max(deg_centrality, key=deg_centrality.get)\n",
        "\tmin_dc = min(deg_centrality, key=deg_centrality.get)\n",
        "\tbet_centrality = nx.betweenness_centrality(g)\n",
        "\tmax_bc = max(bet_centrality, key=bet_centrality.get)\n",
        "\tmin_bc = min(bet_centrality, key=bet_centrality.get)\n",
        "\tcl_centrality = nx.closeness_centrality(g)\n",
        "\tmax_clc = max(cl_centrality, key=cl_centrality.get)\n",
        "\tmin_clc = min(cl_centrality, key=cl_centrality.get)\n",
        "\teig_centrality = nx.eigenvector_centrality(g)\n",
        "\tmax_ec = max(eig_centrality, key=eig_centrality.get)\n",
        "\tmin_ec = min(eig_centrality, key=eig_centrality.get)\n",
        "\n",
        "\tprint(\"------\", k, \"------\")\n",
        "\tprint(\"Interval of degree centrality: [{}, {}]\".format(deg_centrality[min_dc], deg_centrality[max_dc]))\n",
        "\tprint(\"Interval of betweenness centrality: [{}, {}]\".format(bet_centrality[min_bc], bet_centrality[max_bc]))\n",
        "\tprint(\"Interval of closeness centrality: [{}, {}]\".format(cl_centrality[min_clc], cl_centrality[max_clc]))\n",
        "\tprint(\"Interval of eigenvector centrality: [{}, {}]\".format(eig_centrality[min_ec], eig_centrality[max_ec]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esuCGxsRfMkc"
      },
      "source": [
        "ðŸ’¬ : The random grah that reassembles the most the book graph is the **Barbasi**. Overall, it is the one whose metrics approximate more the book graph, with some exceptions like the minimum degree centrality, which others approximate more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEt8rlpHUtoA"
      },
      "source": [
        "* **ðŸ’¬ Check whether the networks (the three randomly generated ones and the network extracted from the books) follow a Power Law.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB5cRKMtUqYQ"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [13, 10]\n",
        "\n",
        "# check power law\n",
        "fig, ax = plt.subplots(4, 1)\n",
        "for i, (k, g) in enumerate(g_dict.items()):\n",
        "\tdegree_sequence = sorted([d for n, d in g.degree()], reverse=True)\n",
        "\tdegreeCount = {i: degree_sequence.count(i) for i in degree_sequence}\n",
        "\tdeg, count = zip(*degreeCount.items())\n",
        "\tax[i].bar(deg, count, width=0.80, color='b')\n",
        "\tax[i].set_title(k)\n",
        "\tax[i].set_xlabel('Degree')\n",
        "\tax[i].set_ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKXBK09dfNfr"
      },
      "source": [
        "ðŸ’¬ : Only the Barbasi random graph follows a Power-law distribution, like the original graph from the book."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}